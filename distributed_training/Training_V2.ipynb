{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd380c-ce32-4fcd-aba5-a8aafa89aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Third-party imports\n",
    "# Standard library imports\n",
    "import warnings\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom imports\n",
    "from datasets import CombinedDataset, MoleculeDataset\n",
    "from protein_processor import ProteinProcessor\n",
    "from model import StackedCrossGraphAttentionModel\n",
    "from utils import setup_logger, collect_protein_node_and_edge_types, pre_filter, collate_fn\n",
    "\n",
    "# Constants\n",
    "RANDOM_SEED = 42\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Set environment variables at the top-level scope\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75d2f9-5aa3-4c21-a2ba-93b0c17b6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_dataset, val_dataset, test_dataset, graph_metadata):\n",
    "        self.logger = setup_logger()\n",
    "        self.model = model\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=64,\n",
    "            num_workers=14,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=64,\n",
    "            num_workers=14,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        \n",
    "        self.test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=64,\n",
    "            num_workers=14,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        # Ensure model is on the correct device before performing the dummy forward pass\n",
    "        self.model = self.model.to(DEVICE)\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        try:\n",
    "            # Set the epoch for the DistributedSampler\n",
    "            self.logger.info(f\"Starting training epoch {epoch}\")\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            for mol_data, prot_data, _ in tqdm(self.train_loader, desc=\"Training\"):\n",
    "                self.optimizer.zero_grad()\n",
    "                mol_data = mol_data.to(DEVICE)\n",
    "                prot_data = prot_data.to(DEVICE)\n",
    "                # print_node_and_edge_info(mol_data)\n",
    "                out = self.model(mol_data, prot_data)\n",
    "                y = mol_data['smolecule'].y.to(DEVICE)\n",
    "                loss = self.criterion(out, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            return total_loss / len(train_loader)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in train_epoch: {e}\")\n",
    "            traceback.print_exc()\n",
    "            raise e\n",
    "\n",
    "    def validate(self):\n",
    "        try:\n",
    "            self.logger.info(f\"Starting validation\")\n",
    "            self.model.eval()\n",
    "            total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for mol_data, prot_data, _ in tqdm(self.val_loader, desc=mode):\n",
    "                    mol_data = mol_data.to(DEVICE)\n",
    "                    prot_data = prot_data.to(DEVICE)\n",
    "                    out = self.model(mol_data, prot_data)\n",
    "                    y = mol_data['smolecule'].y.to(DEVICE)\n",
    "                    loss = self.criterion(out, y)\n",
    "                    total_loss += loss.item()\n",
    "            return total_loss / len(loader)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in validate: {e}\")\n",
    "            traceback.print_exc()\n",
    "            raise e\n",
    "\n",
    "    def test(self):\n",
    "        try:\n",
    "            self.model.eval()\n",
    "            predictions = []\n",
    "            true_labels = []\n",
    "            with torch.no_grad():\n",
    "                for mol_data, prot_data, _ in tqdm(self.test_loader, desc=\"Testing\"):\n",
    "                    mol_data = mol_data.to(DEVICE)\n",
    "                    prot_data = prot_data.to(DEVICE)\n",
    "                    out = self.model(mol_data, prot_data)\n",
    "                    predictions.extend(out.cpu().numpy())\n",
    "                    true_labels.extend(mol_data['smolecule'].y.cpu().numpy())\n",
    "            return predictions, true_labels\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in test: {e}\")\n",
    "            traceback.print_exc()\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e54f7-5819-4d9e-8323-85abccd167d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_dataset, val_dataset, test_dataset, graph_metadata):\n",
    "    # Set random seeds for reproducibility\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "    logger = setup_logger()\n",
    "    logger.info(f\"Starting run function\")\n",
    "\n",
    "    # Initialize model, criterion, and optimizer\n",
    "    model = StackedCrossGraphAttentionModel(graph_metadata, hidden_dim=128, num_attention_heads=8, num_layers=4)\n",
    "    logger.info(f\"Model initialized\")\n",
    "\n",
    "    # Train the model\n",
    "    trainer = Trainer(model, train_dataset, val_dataset, test_dataset, graph_metadata)\n",
    "\n",
    "    num_epochs = 5  # Set your number of epochs\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = trainer.train_epoch(epoch)\n",
    "        val_loss = trainer.validate()\n",
    "        logger.info(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Save the model if it's the best so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # Save the model\n",
    "            torch.save(model.module.state_dict(), 'best_cross_graph_attention_model.pth')\n",
    "            logger.info(f'New best model saved at epoch {epoch}')\n",
    "\n",
    "    test_predictions, test_true = trainer.test()\n",
    "    \n",
    "    # Apply a threshold to obtain binary predictions\n",
    "    threshold = 0.5\n",
    "    test_pred_binary = [1 if p >= threshold else 0 for p in test_predictions]\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(test_true, test_pred_binary)\n",
    "    roc_auc = roc_auc_score(test_true, test_predictions)\n",
    "    precision = precision_score(test_true, test_pred_binary)\n",
    "    recall = recall_score(test_true, test_pred_binary)\n",
    "    f1 = f1_score(test_true, test_pred_binary)\n",
    "\n",
    "    logger.info(\"Test Results:\")\n",
    "    logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "    logger.info(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    logger.info(f\"Precision: {precision:.4f}\")\n",
    "    logger.info(f\"Recall: {recall:.4f}\")\n",
    "    logger.info(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49910e66-0d8b-4f05-99dc-ff6360e49048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_parquet('../cleaned_train.parquet')\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['binds'], random_state=RANDOM_SEED)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['binds'], random_state=RANDOM_SEED)\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "# Process proteins\n",
    "protein_pdb_files = {\n",
    "    'BRD4': '../BRD4.pdb',\n",
    "    'HSA': '../ALB.pdb',\n",
    "    'sEH': '../EPH.pdb'\n",
    "}\n",
    "protein_graphs = {protein_name: ProteinProcessor.process_protein(pdb_file) \n",
    "                  for protein_name, pdb_file in protein_pdb_files.items() if os.path.exists(pdb_file)}\n",
    "\n",
    "# Load unique atom and edge types\n",
    "with open('../unique_atom_and_edge_types.json', 'r') as f:\n",
    "    unique_types = json.load(f)\n",
    "\n",
    "molecule_node_types = unique_types['molecule_node_types']\n",
    "molecule_edge_types = [tuple(edge) for edge in unique_types['molecule_edge_types']]\n",
    "protein_node_types, protein_edge_types = collect_protein_node_and_edge_types(protein_graphs)\n",
    "graph_metadata = {\n",
    "    'molecule_node_types': molecule_node_types,\n",
    "    'molecule_edge_types': molecule_edge_types,\n",
    "    'protein_node_types': protein_node_types,\n",
    "    'protein_edge_types': protein_edge_types\n",
    "}\n",
    "\n",
    "# Create datasets and data loaders\n",
    "train_dataset = CombinedDataset(train_df, protein_graphs)\n",
    "val_dataset = CombinedDataset(val_df, protein_graphs)\n",
    "test_dataset = CombinedDataset(test_df, protein_graphs)\n",
    "run(train_dataset, val_dataset, test_dataset, graph_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5aaf19-8755-4367-bf21-74fa918db983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
